来自 v_JULY_v 的CSDN 博客 ，全文地址请点击：https://blog.csdn.net/v_JULY_v/article/details/6279498?utm_source=copy  

### 1、海量日志数据，提取出某日访问百度次数最多的那个IP。

算法思想：分而治之+Hash 

1.IP地址最多有2^32=4G种取值情况，所以不能完全加载到内存中处理；  

2.可以考虑采用“分而治之”的思想，按照IP地址的Hash(IP)%1024值，把海量IP日志分别存储到1024个小文件中。这样，每个小文件最多包含4MB个IP地址；  

3.对于每一个小文件，可以构建一个IP为key，出现次数为value的Hash map，同时记录当前出现次数最多的那个IP地址； 

4.可以得到1024个小文件中的出现次数最多的IP，再依据常规的排序算法得到总体上出现次数最多的IP；



###2、搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。

​	这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个.然后TopK



### 3 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？

方案1：可以估计每个文件安的大小为5G×64=320G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。     遍历文件a，对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件（记为a0,a1,...,a999）中。这样每个小文件的大约为300M。     遍历文件b，采取和a相同的方式将url分别存储到1000小文件（记为b0,b1,...,b999）。这样处理后，所有可能相同的url都在对应的小文件（a0vsb0,a1vsb1,...,a999vsb999）中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。     求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。     

方案2：如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）。



### 4. 腾讯面试题：给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？

方案1：oo，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。 

方案2： 按位拆分

### 5. 100w个数中找出最大的100个数。     

方案1：在前面的题中，我们已经提到了，用一个含100个元素的最小堆完成。复杂度为O(100w*lg100)。     *

方案2：采用快速排序的思想，每次分割之后只考虑比轴大的一部分，知道比轴大的一部分在比100多的时候，采用传统排序算法排序，取前100个。复杂度为O(100w*100)。     

方案3：采用局部淘汰法。选取前100个元素，并排序，记为序列L



当系统的处理请求时间一定的时候，如何可以加快响应速度。（cache的使用） 

尽量少的线程切换 尽量少的共享冲突 尽量无锁 工作中的线程数尽量等于CPU核心数 尽量没有等待时间片的线程 逻辑尽量简化，避免不必要的封装和转发 



高并发的服务器设计

1.单机服务的性能如何做到极致，即尽量利用最少的硬件资源(CPU、内存、硬盘等)去尽量为多的客户端服务;

epoll这种多路复用就绪通知技术确实适合海量并发长链连接的场景下，与select/poll等相比，它去除了最大连接数的限制，也减少了在内核态和用户态之间复制文件描述符的开销。 

```
 while(!m_Quit){
  // 步骤一：使用select或者epoll_wait等IO复用技术检测socket上是否有读写或出错事件
  // 对于第一个循环，只检测侦听socket是否有事件
  // epoll_or_select_func();
  // 步骤二：检测到某些socket上有事件后处理事件，比如收数据，对于第一个循环可能是
  //接受客户端连接，接收完数据解数据包进行业务逻辑处理
  // handle_io_events();
   //步骤三：做一些其他事情
 }
```



2.单机解决不了的，如何使用一组服务程序高效地协同。